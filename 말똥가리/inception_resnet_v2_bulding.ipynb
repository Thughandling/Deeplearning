{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dir = r\"C:\\dacon\\\\data\\\\\"\n",
    "train_dir = dir + \"dirty_mnist_2nd\\\\\"\n",
    "train_label_dir = pd.read_csv(r\"C:\\dacon\\\\data\\\\dirty_mnist_2nd_answer.csv\")\n",
    "\n",
    "class ToTensor():\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image':torch.FloatTensor(image), 'label':torch.FloatTensor(label)}\n",
    "\n",
    "to_tensor = T.Compose([\n",
    "    # T.Resize((224, 224)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "class Generator(Dataset):\n",
    "    def __init__(self, train_dir, train_label_dir, transforms = to_tensor, augmentations=None):\n",
    "        self.x_data = train_dir\n",
    "        self.x_label = train_label_dir\n",
    "        self.transforms = transforms\n",
    "        self.augmentations = augmentations\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.x_label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        train = cv2.imread(self.train_dir+str(self.x_label.iloc[idx,0]).zfill(5)+'.png', cv2.IMREAD_COLOR)\n",
    "        train = cv2.resize(train,(299, 299) )\n",
    "        train = (train/255).astype('float32')\n",
    "        label = self.x_label.iloc[idx, 1:].values.astype('float32')\n",
    "        sample = {'image':image, 'label':label}\n",
    "        if self.transforms is not None:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold:] 1\n",
      "[fold:] 2\n",
      "[fold:] 3\n",
      "[fold:] 4\n",
      "[fold:] 5\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=False, random_state=0)\n",
    "epoch_size = 5\n",
    "batch_size = 8\n",
    "    \n",
    "best_model = []\n",
    "for fold_index, (train_idx, valid_idx) in enumerate(kfold.split(train_label_dir), 1):\n",
    "        \n",
    "        print(f'[fold:] {fold_index}')\n",
    "        torch.cuda.empty_cache()#gpu에서 메모리 내려놓음\n",
    "        \n",
    "        train_label = train_label_dir.iloc[train_idx]\n",
    "        valid_label = train_label_dir.iloc[valid_idx]\n",
    "        train_image = Generator(train_dir, train_label)\n",
    "        valid_image = Generator(train_dir, valid_label)\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_image,\n",
    "            batch_size=batch_size,\n",
    "            shuffle = False,\n",
    "            num_workers=0                  \n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_image,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0                  \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # bias=Fasle, because BN after conv includes bias.\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, bias=False, **kwargs),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEM\n",
    "class Stem(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            BasicConv2d(3, 32, 3, stride=2, padding=0), # 149 x 149 x 32\n",
    "            BasicConv2d(32, 32, 3, stride=1, padding=0), # 147 x 147 x 32\n",
    "            BasicConv2d(32, 64, 3, stride=1, padding=1), # 147 x 147 x 64 \n",
    "        )\n",
    "\n",
    "        self.branch3x3_conv = BasicConv2d(64, 96, 3, stride=2, padding=0) # 73x73x96\n",
    "\n",
    "        #  kernel_size=4: 피쳐맵 크기 73, kernel_size=3: 피쳐맵 크기 74\n",
    "        self.branch3x3_pool = nn.MaxPool2d(4, stride=2, padding=1) # 73x73x64\n",
    "\n",
    "        self.branch7x7a = nn.Sequential(\n",
    "            BasicConv2d(160, 64, 1, stride=1, padding=0),\n",
    "            BasicConv2d(64, 96, 3, stride=1, padding=0)\n",
    "        ) # 71x71x96\n",
    "\n",
    "        self.branch7x7b = nn.Sequential(\n",
    "            BasicConv2d(160, 64, 1, stride=1, padding=0),\n",
    "            BasicConv2d(64, 64, (7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(64, 64, (1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(64, 96, 3, stride=1, padding=0)\n",
    "        ) # 71x71x96\n",
    "\n",
    "        self.branchpoola = BasicConv2d(192, 192, 3, stride=2, padding=0) # 35x35x192\n",
    "\n",
    "        #  kernel_size=4: 피쳐맵 크기 73, kernel_size=3: 피쳐맵 크기 74\n",
    "        self.branchpoolb = nn.MaxPool2d(4, 2, 1) # 35x35x192\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.cat((self.branch3x3_conv(x), self.branch3x3_pool(x)), dim=1)\n",
    "        x = torch.cat((self.branch7x7a(x), self.branch7x7b(x)), dim=1)\n",
    "        x = torch.cat((self.branchpoola(x), self.branchpoolb(x)), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([3, 3, 299, 299])\n",
      "Stem output size: torch.Size([3, 384, 35, 35])\n"
     ]
    }
   ],
   "source": [
    "# check Stem\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.randn((3, 3, 299, 299)).to(device)\n",
    "model = Stem().to(device)\n",
    "output_Stem = model(x)\n",
    "print('Input size:', x.size())\n",
    "print('Stem output size:', output_Stem.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_Resnet_A(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 32, 1, stride=1, padding=0)\n",
    "\n",
    "        self.branch3x3 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 32, 1, stride=1, padding=0),\n",
    "            BasicConv2d(32, 32, 3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch3x3stack = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 32, 1, stride=1, padding=0),\n",
    "            BasicConv2d(32, 32, 3, stride=1, padding=1),\n",
    "            BasicConv2d(48, 64, 3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.reduction1x1 = nn.Conv2d(128, 384, 1, stride=1, padding=0)\n",
    "        self.shortcut = nn.Conv2d(in_channels, 384, 1, stride=1, padding=0)\n",
    "        self.bn = nn.BatchNorm2d(384)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_shortcut = self.shortcut(x)\n",
    "        x = torch.cat((self.branch1x1(x), self.branch3x3(x), self.branch3x3stack(x)), dim=1)\n",
    "        x = self.reduction1x1(x)\n",
    "        x = self.bn(x_shortcut + x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
